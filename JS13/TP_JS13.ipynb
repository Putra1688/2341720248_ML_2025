{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Putra1688/MachineLearning-2025-22/blob/main/TGS13_2341720248_Rangga_Dwi_Saputra_ANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tuj3Iiw2dVIO"
      },
      "source": [
        "# **JS13 - Artificial Neural Network (ANN) dan Evaluasi Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAdxMKBbsDR4"
      },
      "source": [
        "# TUGAS PRAKTIKUM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXwmJaomsCZl",
        "outputId": "0490c9a2-026a-4e79-a5eb-b1cc5be127de"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.8707 - loss: 0.4528 - val_accuracy: 0.9690 - val_loss: 0.1064\n",
            "Epoch 2/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9659 - loss: 0.1124 - val_accuracy: 0.9752 - val_loss: 0.0865\n",
            "Epoch 3/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9769 - loss: 0.0718 - val_accuracy: 0.9778 - val_loss: 0.0777\n",
            "Epoch 4/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 5ms/step - accuracy: 0.9824 - loss: 0.0535 - val_accuracy: 0.9742 - val_loss: 0.0850\n",
            "Epoch 5/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0388 - val_accuracy: 0.9762 - val_loss: 0.0866\n",
            "Epoch 6/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0310 - val_accuracy: 0.9772 - val_loss: 0.0801\n",
            "Epoch 7/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0254 - val_accuracy: 0.9807 - val_loss: 0.0772\n",
            "Epoch 8/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.0229 - val_accuracy: 0.9793 - val_loss: 0.0794\n",
            "Epoch 9/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9936 - loss: 0.0199 - val_accuracy: 0.9755 - val_loss: 0.1155\n",
            "Epoch 10/10\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.9947 - loss: 0.0162 - val_accuracy: 0.9760 - val_loss: 0.1088\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9689 - loss: 0.1364\n",
            "Akurasi pada data uji: 0.9725\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# 1. Load dataset MNIST\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# 2. Bangun model JST\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor\n",
        "    Dense(128, activation='relu'), # Hidden layer 1\n",
        "    Dense(64, activation='relu'),  # Hidden layer 2\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Latih model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1)\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi pada data uji: {acc:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxBzYJwItm0B"
      },
      "source": [
        "### 1] Ubah jumlah neuron di hidden layer (misal: 256 dan 128) dan Tambahkan satu hidden layer lagi."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccc30d15",
        "outputId": "68793240-d9f4-4daa-946d-c9d63df30a47"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Training Model dengan Arsitektur Baru (256, 128, 64 Neurons) ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waktu pelatihan model baru: 139.08 detik\n",
            "Akurasi pada data uji (model baru): 0.9799\n",
            "Akurasi pada data uji (model awal): 0.9725\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import time\n",
        "\n",
        "# Memuat dataset MNIST (lagi, untuk memastikan konsistensi jika kernel di-reset)\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalisasi data (0-255 → 0-1)\n",
        "X_train = X_train / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# One-hot encoding label\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "print(\"--- Training Model dengan Arsitektur Baru (256, 128, 64 Neurons) ---\")\n",
        "\n",
        "# 2. Bangun model JST dengan arsitektur baru\n",
        "model_new_arch = Sequential([\n",
        "    Flatten(input_shape=(28, 28)), # Ubah gambar 28x28 menjadi vektor\n",
        "    Dense(256, activation='relu'), # Hidden layer 1: Diubah dari 128 menjadi 256\n",
        "    Dense(128, activation='relu'), # Hidden layer 2: Diubah dari 64 menjadi 128\n",
        "    Dense(64, activation='relu'),  # Hidden layer 3: Tambahan layer baru dengan 64 neuron\n",
        "    Dense(10, activation='softmax') # Output layer (10 kelas)\n",
        "])\n",
        "\n",
        "# 3. Kompilasi model\n",
        "model_new_arch.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# 4. Latih model dan ukur waktu pelatihan\n",
        "start_time = time.time()\n",
        "history_new_arch = model_new_arch.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.1, verbose=0) # verbose=0 untuk meringkas output\n",
        "end_time = time.time()\n",
        "training_time_new_arch = end_time - start_time\n",
        "\n",
        "# 5. Evaluasi model\n",
        "loss_new_arch, acc_new_arch = model_new_arch.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "print(f\"Waktu pelatihan model baru: {training_time_new_arch:.2f} detik\")\n",
        "print(f\"Akurasi pada data uji (model baru): {acc_new_arch:.4f}\")\n",
        "\n",
        "# Mengambil akurasi dari model sebelumnya (lXwmJaomsCZl) untuk perbandingan\n",
        "# Diasumsikan variabel `acc` dari eksekusi sebelumnya masih tersedia.\n",
        "# Jika tidak, Anda bisa melatih ulang model awal di sini atau mengambil nilai dari output sebelumnya.\n",
        "print(f\"Akurasi pada data uji (model awal): {acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e6fdf81"
      },
      "source": [
        "### 2] Perbandingan Model MNIST (Arsitektur Lama vs Arsitektur Baru)\n",
        "\n",
        "Berikut adalah perbandingan kinerja model klasifikasi MNIST dengan dua arsitektur Jaringan Saraf Tiruan yang berbeda:\n",
        "\n",
        "| Kriteria             | Model Awal (Flatten, 128, 64, 10) | Model Baru (Flatten, 256, 128, 64, 10) |\n",
        "| :------------------- | :------------------------------- | :------------------------------------- |\n",
        "| **Arsitektur Hidden Layer** | (128, 64)                         | (256, 128, 64)                         |\n",
        "| **Waktu Pelatihan**  | _(Diperlukan eksekusi ulang untuk perbandingan waktu yang akurat)_ | {{training_time_new_arch:.2f}} detik  |\n",
        "| **Akurasi pada Data Uji** | {{acc:.4f}}                       | {{acc_new_arch:.4f}}                   |\n",
        "\n",
        "**Analisis:**\n",
        "\n",
        "*(Catatan: Akurasi dan waktu pelatihan dapat bervariasi karena inisialisasi bobot acak dan perbedaan kondisi eksekusi.)*\n",
        "\n",
        "Dari perbandingan ini, kita akan dapat melihat bagaimana penambahan jumlah neuron dan lapisan tersembunyi dapat memengaruhi kinerja (akurasi) dan kompleksitas komputasi (waktu pelatihan) model. Model dengan arsitektur yang lebih kompleks memiliki potensi untuk menangkap pola yang lebih rumit, namun juga mungkin membutuhkan lebih banyak waktu dan sumber daya untuk pelatihan."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyM9PAI+ICpJlpU//LrWczWd",
      "include_colab_link": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
